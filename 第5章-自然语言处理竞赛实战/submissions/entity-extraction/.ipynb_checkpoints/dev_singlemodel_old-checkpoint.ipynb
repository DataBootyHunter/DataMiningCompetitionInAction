{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f714cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizerFast,AutoModel,NezhaModel,AutoTokenizer\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import  tqdm\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "from roformer import RoFormerModel\n",
    "# from gau_alpha import GAUAlphaModel, GAUAlphaTokenizer,GAUAlphaTokenizerFast\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = \"True\"\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "465eac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#参数\n",
    "device = torch.device(\"cuda\")\n",
    "ENT_CLS_NUM = 9\n",
    "eval_file = '../input/data_label_kfold_v1.1.json'\n",
    "np_save_path = '/home/xmea2059/yk/SereTOD/code/ef_roformer_add_dev/roforer'\n",
    "typeid_path = '../input/type2id.json'\n",
    "batchsize = 32\n",
    "ner_maxlen= 20\n",
    "add_test=False\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "type2id = json.load(open(typeid_path))\n",
    "type2id = {label: (id-1) for label, id in type2id.items() if label !=\"NA\"}\n",
    "id2type = {}\n",
    "for k, v in type2id.items(): id2type[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de0ab5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(type2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92c78d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "##判断最大长度 ----50\n",
    "# data = json.load(open(eval_file))\n",
    "# result = []\n",
    "# def compute_offset_in_turn(triple,turn,text_in_turn,original_pos):\n",
    "#     speaker1 = list(turn.keys())[0]\n",
    "#     # speaker2 = list(turn.keys())[1]\n",
    "#     # start, end = None, None\n",
    "#     if original_pos[0] == 1:\n",
    "#         start, end = original_pos[1:]\n",
    "#     else:\n",
    "#         start = original_pos[1] + len(turn[speaker1])\n",
    "#         end = original_pos[2] + len(turn[speaker1])\n",
    "#     text1 = (\"\".join(text_in_turn[start:end])).replace(\"_\",\" \")\n",
    "#     text2 = triple[\"value\"].replace(\"_\",\" \")\n",
    "#     assert text1==text2\n",
    "#     if text_in_turn[start] ==' ' or text_in_turn[start] =='_':\n",
    "#         start += 1\n",
    "#     if text_in_turn[end-1] ==' ' or text_in_turn[end-1] =='_':\n",
    "#         end -= 1\n",
    "#     type_lable = triple['prop']\n",
    "#     return (end-start,type_lable)\n",
    "\n",
    "\n",
    "# for item in tqdm(data, desc=\"Reading\"):\n",
    "#     for turn in item[\"content\"]:\n",
    "#         if 'is_traing' in turn and turn['is_traing'] != 'true':\n",
    "#             continue\n",
    "#         text_in_turn_list = []\n",
    "#         for key in list(turn.keys())[:2]:\n",
    "#             text_in_turn_list.append(turn[key])\n",
    "#         text_in_turn = list(\"\".join(text_in_turn_list))\n",
    "#         for triple in turn[\"info\"][\"triples\"]:\n",
    "#             if triple['prop'] =='故障问题' or triple['prop'] =='业务规则':\n",
    "#                 continue\n",
    "#             offset = compute_offset_in_turn(triple,turn,text_in_turn,triple[\"pos\"])\n",
    "#             result.append(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ccb484e-74aa-4daa-834c-7808c609ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#去除噪音\n",
    "noisy_tokens = [\" \", \"_\"]\n",
    "specific_ents = [\n",
    "    \"积分倍享合约\",\n",
    "    \"停开机\",\n",
    "    \"手机报\",\n",
    "    \"139邮箱\",\n",
    "    \"来电提醒\",\n",
    "    \"和对讲个人版\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2467ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG1:\n",
    "    num_workers=4\n",
    "    path=\"/data/user0731/yk/SereTOD/code_final/ee_macbert_add_dev/\"\n",
    "    model=\"/data/user0731/yk/SereTOD/pretrain/mac_bert_base\"\n",
    "    batch_size=32\n",
    "    max_len=256\n",
    "    folds=4\n",
    "    seed=42\n",
    "# class CFG2:\n",
    "#     num_workers=4\n",
    "#     path=\"/home/user0731/yankuo/SereTOD/output_model/globpointer/macbert/ent_model.pth\"\n",
    "#     model=\"/home/user0731/yankuo/SereTOD/output_model/pretrain/macbert_base_lm\"\n",
    "#     batch_size=32\n",
    "#     max_len=384\n",
    "#     seed=42\n",
    "# class CFG3:\n",
    "#     num_workers=4\n",
    "#     path=\"/home/user0731/yankuo/SereTOD/output_model/globpointer/nezha_wwm/ent_model.pth\"\n",
    "#     model=\"/home/user0731/yankuo/SereTOD/model/nazha_wwm\"\n",
    "#     batch_size=32\n",
    "#     max_len=256\n",
    "#     seed=42\n",
    "# class CFG4:\n",
    "#     num_workers=4\n",
    "#     path=\"/home/user0731/yankuo/SereTOD/output_model/globpointer/deberta_base_lm0812/ent_model.pth\"\n",
    "#     model=\"/home/user0731/yankuo/SereTOD/output_model/pretrain/deberta_base_lm\"\n",
    "#     batch_size=32\n",
    "#     max_len=256\n",
    "#     seed=42\n",
    "# class CFG5:\n",
    "#     num_workers=4\n",
    "#     path=\"/home/user0731/yankuo/SereTOD/output_model/globpointer/chinese_gau_lm/ent_model.pth\"\n",
    "#     model=\"/home/user0731/yankuo/SereTOD/output_model/pretrain/chinese_gau_lm\"\n",
    "#     batch_size=32\n",
    "#     max_len=256\n",
    "#     seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3840b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG1.tokenizer = AutoTokenizer.from_pretrained(CFG1.model)\n",
    "# CFG2.tokenizer = AutoTokenizer.from_pretrained(CFG2.model)\n",
    "# CFG3.tokenizer = AutoTokenizer.from_pretrained(CFG3.model)\n",
    "# CFG4.tokenizer = AutoTokenizer.from_pretrained(CFG4.model)\n",
    "# CFG5.tokenizer = GAUAlphaTokenizerFast.from_pretrained(CFG5.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fdb6558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data):\n",
    "    D = []\n",
    "#     data = json.load(open(data))\n",
    "    for item in tqdm(data, desc=\"Reading\"):\n",
    "        # i=0\n",
    "        first_line = []  # 缓存所有的对话文本\n",
    "        for turn in item[\"content\"]:\n",
    "            # text in turn\n",
    "            text_in_turn_list = []\n",
    "            for key in list(turn.keys())[:2]:\n",
    "                text_in_turn_list.append(turn[key])\n",
    "            text_in_turn = list(\"\".join(text_in_turn_list))\n",
    "            first_line += text_in_turn\n",
    "\n",
    "        # first_line = \"\".join(first_line)\n",
    "\n",
    "        for turn in item[\"content\"]:\n",
    "            text_in_turn_list = []\n",
    "            for key in list(turn.keys())[:2]:\n",
    "                text_in_turn_list.append(turn[key])\n",
    "            text_in_turn = list(\"\".join(text_in_turn_list))\n",
    "            D.append([text_in_turn])\n",
    "            D[-1].append(first_line)\n",
    "    return D\n",
    "\n",
    "class EntDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer,max_len,istrain=True):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.istrain = istrain\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def encoder(self, item):\n",
    "        if self.istrain:\n",
    "            text = item[0]\n",
    "            text_context = item[1]\n",
    "            text_mapping = self.tokenizer(text,max_length=self.max_len, truncation=True,is_split_into_words=True)\n",
    "            word_ids = text_mapping.word_ids()\n",
    "            token_lengh = len(word_ids)-1\n",
    "            # start_mapping = {j[0]: i for i, j in enumerate(token2char_span_mapping) if j != (0, 0)}\n",
    "            # end_mapping = {j[-1]: i for i, j in enumerate(token2char_span_mapping) if j != (0, 0)}\n",
    "            #将raw_text的下标 与 token的start和end下标对应\n",
    "            text_all = text+text_context\n",
    "            encoder_txt = self.tokenizer(text_all, max_length=self.max_len, truncation=True,is_split_into_words=True)\n",
    "            input_ids = encoder_txt[\"input_ids\"]\n",
    "            token_type_ids = encoder_txt[\"token_type_ids\"]\n",
    "            attention_mask = encoder_txt[\"attention_mask\"]\n",
    "\n",
    "            return text, input_ids, token_type_ids, attention_mask,token_lengh,word_ids\n",
    "        else:\n",
    "            #TODO 测试\n",
    "            pass\n",
    "\n",
    "    def sequence_padding(self, inputs, length=None, value=0, seq_dims=1, mode='post'):\n",
    "        \"\"\"Numpy函数，将序列padding到同一长度\n",
    "        \"\"\"\n",
    "        if length is None:\n",
    "            length = np.max([np.shape(x)[:seq_dims] for x in inputs], axis=0)\n",
    "        elif not hasattr(length, '__getitem__'):\n",
    "            length = [length]\n",
    "\n",
    "        slices = [np.s_[:length[i]] for i in range(seq_dims)]\n",
    "        slices = tuple(slices) if len(slices) > 1 else slices[0]\n",
    "        pad_width = [(0, 0) for _ in np.shape(inputs[0])]\n",
    "\n",
    "        outputs = []\n",
    "        for x in inputs:\n",
    "            x = x[slices]\n",
    "            for i in range(seq_dims):\n",
    "                if mode == 'post':\n",
    "                    pad_width[i] = (0, length[i] - np.shape(x)[i])\n",
    "                elif mode == 'pre':\n",
    "                    pad_width[i] = (length[i] - np.shape(x)[i], 0)\n",
    "                else:\n",
    "                    raise ValueError('\"mode\" argument must be \"post\" or \"pre\".')\n",
    "            x = np.pad(x, pad_width, 'constant', constant_values=value)\n",
    "            outputs.append(x)\n",
    "\n",
    "        return np.array(outputs)\n",
    "\n",
    "    def collate(self, examples):\n",
    "        batch_input_ids, batch_attention_mask, batch_segment_ids,batch_token_lengh,batch_word_ids = [], [], [],[],[]\n",
    "        for item in examples:\n",
    "            raw_text, input_ids, token_type_ids, attention_mask,token_lengh,word_ids = self.encoder(item)\n",
    "            batch_input_ids.append(input_ids)\n",
    "            batch_segment_ids.append(token_type_ids)\n",
    "            batch_attention_mask.append(attention_mask)\n",
    "            batch_token_lengh.append([1]*token_lengh)\n",
    "            batch_word_ids.append(word_ids)\n",
    "        batch_inputids = torch.tensor(self.sequence_padding(batch_input_ids)).long()\n",
    "        batch_segmentids = torch.tensor(self.sequence_padding(batch_segment_ids)).long()\n",
    "        batch_attentionmask = torch.tensor(self.sequence_padding(batch_attention_mask)).float()\n",
    "\n",
    "        max_lengh = batch_inputids.shape[1]\n",
    "        batch_token_lengh = torch.tensor(self.sequence_padding(batch_token_lengh,length=max_lengh)).float()\n",
    "\n",
    "\n",
    "        return batch_inputids, batch_attentionmask, batch_segmentids,batch_token_lengh,batch_word_ids\n",
    "    def __getitem__(self, index):\n",
    "        item = self.data[index]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a890d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalPointer(nn.Module):\n",
    "    def __init__(self, encoder, ent_type_size, inner_dim, RoPE=True):\n",
    "        #encodr: RoBerta-Large as encoder\n",
    "        #inner_dim: 64\n",
    "        #ent_type_size: ent_cls_num\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.ent_type_size = ent_type_size\n",
    "        self.inner_dim = inner_dim\n",
    "        self.hidden_size = encoder.config.hidden_size\n",
    "        self.dense = nn.Linear(self.hidden_size, self.ent_type_size * self.inner_dim * 2)\n",
    "\n",
    "        self.RoPE = RoPE\n",
    "\n",
    "\n",
    "    def sinusoidal_position_embedding(self, batch_size, seq_len, output_dim):\n",
    "        position_ids = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(-1)\n",
    "\n",
    "        indices = torch.arange(0, output_dim // 2, dtype=torch.float)\n",
    "        indices = torch.pow(10000, -2 * indices / output_dim)\n",
    "        embeddings = position_ids * indices\n",
    "        embeddings = torch.stack([torch.sin(embeddings), torch.cos(embeddings)], dim=-1)\n",
    "        embeddings = embeddings.repeat((batch_size, *([1]*len(embeddings.shape))))\n",
    "        embeddings = torch.reshape(embeddings, (batch_size, seq_len, output_dim))\n",
    "        embeddings = embeddings.to(self.device)\n",
    "        return embeddings\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids,token_lengh):\n",
    "        self.device = input_ids.device\n",
    "        \n",
    "        context_outputs = self.encoder(input_ids, attention_mask, token_type_ids)\n",
    "        # last_hidden_state:(batch_size, seq_len, hidden_size)\n",
    "        last_hidden_state = context_outputs[0]\n",
    "\n",
    "        batch_size = last_hidden_state.size()[0]\n",
    "        seq_len = last_hidden_state.size()[1]\n",
    "\n",
    "        # outputs:(batch_size, seq_len, ent_type_size*inner_dim*2)\n",
    "        outputs = self.dense(last_hidden_state)\n",
    "        outputs = torch.split(outputs, self.inner_dim * 2, dim=-1)\n",
    "        # outputs:(batch_size, seq_len, ent_type_size, inner_dim*2)\n",
    "        outputs = torch.stack(outputs, dim=-2)\n",
    "        # qw,kw:(batch_size, seq_len, ent_type_size, inner_dim)\n",
    "        qw, kw = outputs[...,:self.inner_dim], outputs[...,self.inner_dim:]\n",
    "        if self.RoPE:\n",
    "            # pos_emb:(batch_size, seq_len, inner_dim)\n",
    "            pos_emb = self.sinusoidal_position_embedding(batch_size, seq_len, self.inner_dim)\n",
    "            # cos_pos,sin_pos: (batch_size, seq_len, 1, inner_dim)\n",
    "            cos_pos = pos_emb[..., None, 1::2].repeat_interleave(2, dim=-1)\n",
    "            sin_pos = pos_emb[..., None,::2].repeat_interleave(2, dim=-1)\n",
    "            qw2 = torch.stack([-qw[..., 1::2], qw[...,::2]], -1)\n",
    "            qw2 = qw2.reshape(qw.shape)\n",
    "            qw = qw * cos_pos + qw2 * sin_pos\n",
    "            kw2 = torch.stack([-kw[..., 1::2], kw[...,::2]], -1)\n",
    "            kw2 = kw2.reshape(kw.shape)\n",
    "            kw = kw * cos_pos + kw2 * sin_pos\n",
    "        # logits:(batch_size, ent_type_size, seq_len, seq_len)\n",
    "        logits = torch.einsum('bmhd,bnhd->bhmn', qw, kw)\n",
    "\n",
    "        # padding mask\n",
    "        pad_mask = token_lengh.unsqueeze(1).unsqueeze(1).expand(batch_size, self.ent_type_size, seq_len, seq_len)\n",
    "        logits = logits*pad_mask - (1-pad_mask)*1e12\n",
    "\n",
    "        # 排除下三角\n",
    "        mask = torch.tril(torch.ones_like(logits), -1)\n",
    "        logits = logits - mask * 1e12\n",
    "\n",
    "        return logits/self.inner_dim**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54df18b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionEmbedding(nn.Module):\n",
    "    \"\"\"定义Sin-Cos位置Embedding\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, output_dim, merge_mode='add', custom_position_ids=False):\n",
    "        super(SinusoidalPositionEmbedding, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.merge_mode = merge_mode\n",
    "        self.custom_position_ids = custom_position_ids\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if self.custom_position_ids:\n",
    "            seq_len = inputs.shape[1]\n",
    "            inputs, position_ids = inputs\n",
    "            position_ids = position_ids.type(torch.float)\n",
    "        else:\n",
    "            input_shape = inputs.shape\n",
    "            batch_size, seq_len = input_shape[0], input_shape[1]\n",
    "            position_ids = torch.arange(seq_len).type(torch.float)[None]\n",
    "        indices = torch.arange(self.output_dim // 2).type(torch.float)\n",
    "        indices = torch.pow(10000.0, -2 * indices / self.output_dim)\n",
    "        embeddings = torch.einsum('bn,d->bnd', position_ids, indices)\n",
    "        embeddings = torch.stack([torch.sin(embeddings), torch.cos(embeddings)], dim=-1)\n",
    "        embeddings = torch.reshape(embeddings, (-1, seq_len, self.output_dim))\n",
    "        if self.merge_mode == 'add':\n",
    "            return inputs + embeddings.to(inputs.device)\n",
    "        elif self.merge_mode == 'mul':\n",
    "            return inputs * (embeddings + 1.0).to(inputs.device)\n",
    "        elif self.merge_mode == 'zero':\n",
    "            return embeddings.to(inputs.device)\n",
    "class EffiGlobalPointer(nn.Module):\n",
    "    def __init__(self, encoder, ent_type_size, inner_dim, RoPE=True,fp16=False):\n",
    "        # encodr: RoBerta-Large as encoder\n",
    "        # inner_dim: 64\n",
    "        # ent_type_size: ent_cls_num\n",
    "        super(EffiGlobalPointer, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.ent_type_size = ent_type_size\n",
    "        self.inner_dim = inner_dim\n",
    "        self.hidden_size = encoder.config.hidden_size\n",
    "        self.RoPE = RoPE\n",
    "        self.fp16=fp16\n",
    "        if fp16:\n",
    "            self.epsilon=65504\n",
    "        else:\n",
    "            self.epsilon =1e12\n",
    "\n",
    "        self.dense_1 = nn.Linear(self.hidden_size, self.inner_dim * 2)\n",
    "        self.dense_2 = nn.Linear(self.hidden_size,\n",
    "                                 self.ent_type_size * 2)  # 原版的dense2是(inner_dim * 2, ent_type_size * 2)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "\n",
    "    def sequence_masking(self, x, mask, value='-inf', axis=None):\n",
    "\n",
    "        if mask is None:\n",
    "            return x\n",
    "        else:\n",
    "            if value == '-inf':\n",
    "                value = -self.epsilon\n",
    "            elif value == 'inf':\n",
    "                value = self.epsilon\n",
    "            assert axis > 0, 'axis must be greater than 0'\n",
    "            for _ in range(axis - 1):\n",
    "                mask = torch.unsqueeze(mask, 1)\n",
    "            for _ in range(x.ndim - mask.ndim):\n",
    "                mask = torch.unsqueeze(mask, mask.ndim)\n",
    "            return x * mask + value * (1 - mask)\n",
    "\n",
    "    def add_mask_tril(self, logits, mask):\n",
    "        if mask.dtype != logits.dtype:\n",
    "            mask = mask.type(logits.dtype)\n",
    "        logits = self.sequence_masking(logits, mask, '-inf', logits.ndim - 2)\n",
    "        logits = self.sequence_masking(logits, mask, '-inf', logits.ndim - 1)\n",
    "        # 排除下三角\n",
    "        mask = torch.tril(torch.ones_like(logits), diagonal=-1)\n",
    "        logits = logits - mask * self.epsilon\n",
    "        return logits\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids,token_lengh):\n",
    "        self.device = input_ids.device\n",
    "\n",
    "        context_outputs = self.encoder(input_ids, attention_mask, token_type_ids)\n",
    "        last_hidden_state = context_outputs.last_hidden_state\n",
    "        # batch_size = last_hidden_state.size()[0]\n",
    "        # seq_len = last_hidden_state.size()[1]\n",
    "        # outputs = self.dense_1(last_hidden_state)\n",
    "        out = self.drop(last_hidden_state)\n",
    "        logits1 = self.dense_1(self.dropout1(out))\n",
    "        logits2 = self.dense_1(self.dropout2(out))\n",
    "        logits3 = self.dense_1(self.dropout3(out))\n",
    "        logits4 = self.dense_1(self.dropout4(out))\n",
    "        logits5 = self.dense_1(self.dropout5(out))\n",
    "        outputs = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n",
    "\n",
    "        qw, kw = outputs[..., ::2], outputs[..., 1::2]  # 从0,1开始间隔为2\n",
    "        if self.RoPE:\n",
    "            pos = SinusoidalPositionEmbedding(self.inner_dim, 'zero')(outputs)\n",
    "            cos_pos = pos[..., 1::2].repeat_interleave(2, dim=-1)\n",
    "            sin_pos = pos[..., ::2].repeat_interleave(2, dim=-1)\n",
    "            qw2 = torch.stack([-qw[..., 1::2], qw[..., ::2]], 3)\n",
    "            qw2 = torch.reshape(qw2, qw.shape)\n",
    "            qw = qw * cos_pos + qw2 * sin_pos\n",
    "            kw2 = torch.stack([-kw[..., 1::2], kw[..., ::2]], 3)\n",
    "            kw2 = torch.reshape(kw2, kw.shape)\n",
    "            kw = kw * cos_pos + kw2 * sin_pos\n",
    "        logits = torch.einsum('bmd,bnd->bmn', qw, kw) / self.inner_dim ** 0.5\n",
    "        bias = torch.einsum('bnh->bhn', self.dense_2(last_hidden_state)) / 2\n",
    "        logits = logits[:, None] + bias[:, ::2, None] + bias[:, 1::2, :, None]  # logits[:, None] 增加一个维度\n",
    "        # print(token_lengh.size())\n",
    "        # pad_mask = token_lengh.unsqueeze(1).unsqueeze(1).expand(batch_size, self.ent_type_size, seq_len, seq_len)\n",
    "        # pad_mask = token_lengh.unsqueeze(1).unsqueeze(1).expand(batch_size, seq_len)\n",
    "        # print(pad_mask.size(),attention_mask.size())\n",
    "        # logits = self.add_mask_tril(logits, mask=attention_mask)\n",
    "        logits = self.add_mask_tril(logits, mask=token_lengh)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "658cf0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(logits, batch_tag,batchsize,batch_word_ids,fold_prob):\n",
    "    # batch_size, ent_type_size, seq_len, seq_len\n",
    "    pred_prob = logits.sigmoid()\n",
    "    sample_num = pred_prob.shape[0]\n",
    "    max_len = min(pred_prob.shape[2],256)\n",
    "    start_index = batch_tag*batchsize\n",
    "    for i in range(max_len):\n",
    "        span = min(ner_maxlen,max_len-i)\n",
    "        fold_prob[start_index:start_index+sample_num,:,i,:span]+=pred_prob[:,:,i,i:i+span].cpu().detach().numpy()\n",
    "    return fold_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69d522bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#单模型\n",
    "def inference_fn(test_loader, model, device,fold_prob):\n",
    "#     no_mark_num = 0\n",
    "#     pred_all = []\n",
    "#     true_all = []\n",
    "    model.eval()\n",
    "    tk0 = tqdm(test_loader,total=len(test_loader))\n",
    "    for batch_index,batch in enumerate(tk0):\n",
    "        input_ids, attention_mask, segment_ids,token_lengh,batch_word_ids = batch\n",
    "        input_ids, attention_mask, segment_ids,token_lengh = input_ids.to(device), attention_mask.to(\n",
    "            device), segment_ids.to(device),token_lengh.to(device)\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_ids, attention_mask, segment_ids,token_lengh)\n",
    "                fold_prob = get_pred(logits,batch_index,batchsize,batch_word_ids,fold_prob)\n",
    "    return fold_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab1df567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../input/data_label_kfold_v1.1.json'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4cbe746",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = json.load(open(eval_file))\n",
    "# sample_num = 0\n",
    "# for item in tqdm(data, desc=\"Reading\" ):\n",
    "#     sample_num += len(item[\"content\"])\n",
    "# print(sample_num)\n",
    "# prob_result = np.zeros((sample_num,ENT_CLS_NUM,256,ner_maxlen),dtype= np.float32)\n",
    "# final_prob= [np.zeros((sample_num,ENT_CLS_NUM,256,ner_maxlen),dtype= np.float16)]*(CFG1.folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5cea19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_all = [CFG1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5547036d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:00<00:00, 208609.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:00<00:00, 4870.57it/s]\n",
      "Some weights of the model checkpoint at /data/user0731/yk/SereTOD/pretrain/mac_bert_base were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at /data/user0731/yk/SereTOD/pretrain/mac_bert_base and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 873/873 [03:53<00:00,  3.74it/s]\n"
     ]
    }
   ],
   "source": [
    "final_prob= []\n",
    "for i,cfg in enumerate(cfg_all):\n",
    "    for fold in [3]:\n",
    "        \n",
    "        valid_folds = []\n",
    "        for value in data:\n",
    "            if value['fold'] == fold:\n",
    "                valid_folds.append(value)\n",
    "        sample_num = 0\n",
    "        for item in tqdm(valid_folds, desc=\"Reading\" ):\n",
    "            for turn in item[\"content\"]:\n",
    "                sample_num += 1\n",
    "        print(sample_num)\n",
    "        #概率矩阵初始化\n",
    "        fold_prob= np.zeros((sample_num,ENT_CLS_NUM,256,ner_maxlen),dtype= np.float16)\n",
    "        ner_evl = EntDataset(load_data(valid_folds), tokenizer=cfg.tokenizer,max_len=cfg.max_len)\n",
    "        ner_loader_evl = DataLoader(ner_evl, batch_size=cfg.batch_size, collate_fn=ner_evl.collate,shuffle=False,num_workers=cfg.num_workers)\n",
    "        if i == 4:\n",
    "            encoder = RoFormerModel.from_pretrained(cfg.model)\n",
    "        elif i == 3:\n",
    "            encoder = GAUAlphaModel.from_pretrained(cfg.model)\n",
    "        else:\n",
    "            encoder = AutoModel.from_pretrained(cfg.model)\n",
    "        if i==1:\n",
    "            model = EffiGlobalPointer(encoder, ENT_CLS_NUM, 64, fp16=True).to(device)\n",
    "        else:\n",
    "            model = GlobalPointer(encoder, ENT_CLS_NUM, 64).to(device)\n",
    "        # print(cfg.path+f\"ent_model{fold}.pth\")\n",
    "        state = torch.load(cfg.path+f\"ent_model{fold}.pth\",map_location=device)\n",
    "        model.load_state_dict(state)\n",
    "        fold_prob = inference_fn(ner_loader_evl,model,device,fold_prob)\n",
    "        final_prob.append(fold_prob)\n",
    "        del encoder,model,state,fold_prob;gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bdd76ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存\n",
    "# np.savez_compressed(np_save_path, fold0=final_prob[0],fold1=final_prob[1],fold2=final_prob[2],fold3=final_prob[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04d3afd2-ffb1-4e70-80bb-b3015fd6f393",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = []\n",
    "for i,value in enumerate(final_prob[0]):\n",
    "    pred = []\n",
    "    for l,start,end in zip(*np.where(value> 0.5)):\n",
    "        prob = value[l][start][end]\n",
    "        pred.append((l,start, start+end,prob))\n",
    "    pred.sort(key=lambda x: (x[1], x[2]),reverse=False)\n",
    "    pred_result.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52851b28-af78-4324-8992-8d54485773a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27910, 9, 256, 20)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prob[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03274006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27910"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dfe998b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_offset_in_turn(ent,turn,text_in_turn,original_pos):\n",
    "    speaker1 = list(turn.keys())[0]\n",
    "    # speaker2 = list(turn.keys())[1]\n",
    "    # start, end = None, None\n",
    "    if original_pos[0] == 1:\n",
    "        start, end = original_pos[1:]\n",
    "    else:\n",
    "        start = original_pos[1] + len(turn[speaker1])\n",
    "        end = original_pos[2] + len(turn[speaker1])\n",
    "    text1 = (\"\".join(text_in_turn[start:end])).replace(\"_\",\" \")\n",
    "    text2 = ent[\"name\"].replace(\"_\",\" \")\n",
    "    assert text1 == text2\n",
    "    if text_in_turn[start] ==' ' or text_in_turn[start] =='_':\n",
    "        start += 1\n",
    "    if text_in_turn[end-1] ==' ' or text_in_turn[end-1] =='_':\n",
    "        end -= 1\n",
    "    type_lable = type2id[ent['type']]\n",
    "    return (start,end-1,type_lable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0badca8b-45c4-41ff-b520-57316832b8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 1110632.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5448150581687473 total_common:7048,total_pred:12858,total_true:13015\n"
     ]
    }
   ],
   "source": [
    "pred_char = []\n",
    "true_char = []\n",
    "idx = 0\n",
    "valid_folds = []\n",
    "for value in tqdm(data):\n",
    "    if value['fold'] == 3:\n",
    "        valid_folds.append(value)\n",
    "for item in valid_folds:\n",
    "    for turn in item[\"content\"]:\n",
    "        text_in_turn_list = []\n",
    "        for key in list(turn.keys())[:2]:\n",
    "            text_in_turn_list.append(turn[key])\n",
    "        text_in_turn = list(\"\".join(text_in_turn_list))\n",
    "        text_mapping = CFG1.tokenizer(text_in_turn,is_split_into_words=True)\n",
    "        word_ids = text_mapping.word_ids()\n",
    "        \n",
    "        temp_pred = []\n",
    "        for preds_sample in pred_result[idx]:\n",
    "            lable = preds_sample[0]\n",
    "            start_char = word_ids[preds_sample[1]]\n",
    "            end_char = word_ids[preds_sample[2]]\n",
    "            prob = preds_sample[3]\n",
    "            if start_char is not None and end_char is not None:\n",
    "                if len(temp_pred)!=0 and start_char <= temp_pred[-1][3]:\n",
    "                    if prob > temp_prob:\n",
    "                        temp_pred.pop()\n",
    "                    else:\n",
    "                        continue\n",
    "                temp_pred.append((idx,lable,start_char,end_char))\n",
    "                temp_prob = prob\n",
    "                \n",
    "        pred_char += temp_pred\n",
    "        for ent in turn[\"info\"][\"ents\"]:\n",
    "            if ent['type'] == '5G套餐':\n",
    "                continue\n",
    "            for position in ent[\"pos\"]:\n",
    "                offset = compute_offset_in_turn(ent,turn,text_in_turn,position)\n",
    "                true_char.append((idx,offset[2],offset[0],offset[1]))\n",
    "        idx += 1\n",
    "R = set(pred_char)\n",
    "T = set(true_char)\n",
    "total_common = len(R & T)\n",
    "total_pred = len(R)\n",
    "total_true = len(T)\n",
    "f1, precision, recall = 2 * total_common / (total_pred + total_true), total_common / total_pred, total_common / total_true\n",
    "print(f1,\"total_common:{},total_pred:{},total_true:{}\".format(total_common, total_pred,total_true))\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
