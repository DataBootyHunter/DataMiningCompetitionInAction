{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f714cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizerFast,AutoModel,NezhaModel,AutoTokenizer\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import  tqdm\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "from roformer import RoFormerModel\n",
    "# from gau_alpha import GAUAlphaModel, GAUAlphaTokenizer,GAUAlphaTokenizerFast\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = \"True\"\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "465eac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#参数\n",
    "device = torch.device(\"cuda\")\n",
    "ENT_CLS_NUM = 9\n",
    "eval_file = '../input/dev_data.json'\n",
    "np_save_path = 'roformer/roforer'\n",
    "type2id_path = '../input/type2id.json'\n",
    "batchsize = 32\n",
    "ner_maxlen= 20\n",
    "add_test=False\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "type2id = json.load(open(type2id_path))\n",
    "type2id = {label: (id-1) for label, id in type2id.items() if label !=\"NA\"}\n",
    "id2type = {}\n",
    "for k, v in type2id.items(): id2type[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ccb484e-74aa-4daa-834c-7808c609ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#去除噪音\n",
    "noisy_tokens = [\" \", \"_\"]\n",
    "specific_ents = [\n",
    "    \"积分倍享合约\",\n",
    "    \"停开机\",\n",
    "    \"手机报\",\n",
    "    \"139邮箱\",\n",
    "    \"来电提醒\",\n",
    "    \"和对讲个人版\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2467ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG1:\n",
    "    num_workers=4\n",
    "    path=\"/home/user0731/yankuo/SereTOD/meric/output_model/roformer/\"\n",
    "    model=\"/home/user0731/yankuo/SereTOD/pretrain/roformer\"\n",
    "    batch_size=32\n",
    "    max_len=256\n",
    "    folds=4\n",
    "    seed=42\n",
    "# class CFG2:\n",
    "#     num_workers=4\n",
    "#     path=\"/home/user0731/yankuo/SereTOD/output_model/globpointer/macbert/ent_model.pth\"\n",
    "#     model=\"/home/user0731/yankuo/SereTOD/output_model/pretrain/macbert_base_lm\"\n",
    "#     batch_size=32\n",
    "#     max_len=384\n",
    "#     seed=42\n",
    "# class CFG3:\n",
    "#     num_workers=4\n",
    "#     path=\"/home/user0731/yankuo/SereTOD/output_model/globpointer/nezha_wwm/ent_model.pth\"\n",
    "#     model=\"/home/user0731/yankuo/SereTOD/model/nazha_wwm\"\n",
    "#     batch_size=32\n",
    "#     max_len=256\n",
    "#     seed=42\n",
    "# class CFG4:\n",
    "#     num_workers=4\n",
    "#     path=\"/home/user0731/yankuo/SereTOD/output_model/globpointer/deberta_base_lm0812/ent_model.pth\"\n",
    "#     model=\"/home/user0731/yankuo/SereTOD/output_model/pretrain/deberta_base_lm\"\n",
    "#     batch_size=32\n",
    "#     max_len=256\n",
    "#     seed=42\n",
    "# class CFG5:\n",
    "#     num_workers=4\n",
    "#     path=\"/home/user0731/yankuo/SereTOD/output_model/globpointer/chinese_gau_lm/ent_model.pth\"\n",
    "#     model=\"/home/user0731/yankuo/SereTOD/output_model/pretrain/chinese_gau_lm\"\n",
    "#     batch_size=32\n",
    "#     max_len=256\n",
    "#     seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3840b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG1.tokenizer = AutoTokenizer.from_pretrained(CFG1.model)\n",
    "# CFG2.tokenizer = AutoTokenizer.from_pretrained(CFG2.model)\n",
    "# CFG3.tokenizer = AutoTokenizer.from_pretrained(CFG3.model)\n",
    "# CFG4.tokenizer = AutoTokenizer.from_pretrained(CFG4.model)\n",
    "# CFG5.tokenizer = GAUAlphaTokenizerFast.from_pretrained(CFG5.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fdb6558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_offset_in_turn(ent,turn, original_pos):\n",
    "    speaker1 = list(turn.keys())[0]\n",
    "    speaker2 = list(turn.keys())[1]\n",
    "    start, end = None, None\n",
    "    if original_pos[0] == 1:\n",
    "        start, end = original_pos[1:]\n",
    "    else:\n",
    "        start = original_pos[1] + len(turn[speaker1])\n",
    "        end = original_pos[2] + len(turn[speaker1])\n",
    "    if ent['type'] != '5G套餐':\n",
    "        type_lable = type2id[ent['type']]\n",
    "        return (start,end,type_lable)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def load_data(path):\n",
    "    D = []\n",
    "    data = json.load(open(path))\n",
    "    for item in tqdm(data, desc=\"Reading from %s\" % path):\n",
    "        # i=0\n",
    "        first_line = []  # 缓存所有的对话文本\n",
    "        for turn in item[\"content\"]:\n",
    "            # text in turn\n",
    "            text_in_turn_list = []\n",
    "            for key in list(turn.keys())[:2]:\n",
    "                text_in_turn_list.append(turn[key])\n",
    "            text_in_turn = list(\"\".join(text_in_turn_list))\n",
    "            first_line += text_in_turn\n",
    "\n",
    "        # first_line = \"\".join(first_line)\n",
    "\n",
    "        for turn in item[\"content\"]:\n",
    "            text_in_turn_list = []\n",
    "            for key in list(turn.keys())[:2]:\n",
    "                text_in_turn_list.append(turn[key])\n",
    "            text_in_turn = list(\"\".join(text_in_turn_list))\n",
    "            D.append([text_in_turn])\n",
    "            D[-1].append(first_line)\n",
    "    return D\n",
    "\n",
    "class EntDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer,max_len,istrain=True):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.istrain = istrain\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def encoder(self, item):\n",
    "        if self.istrain:\n",
    "            text = item[0]\n",
    "            text_context = item[1]\n",
    "            text_mapping = self.tokenizer(text,max_length=self.max_len, truncation=True,is_split_into_words=True)\n",
    "            word_ids = text_mapping.word_ids()\n",
    "            token_lengh = len(word_ids)-1\n",
    "            # start_mapping = {j[0]: i for i, j in enumerate(token2char_span_mapping) if j != (0, 0)}\n",
    "            # end_mapping = {j[-1]: i for i, j in enumerate(token2char_span_mapping) if j != (0, 0)}\n",
    "            #将raw_text的下标 与 token的start和end下标对应\n",
    "            text_all = text+text_context\n",
    "            encoder_txt = self.tokenizer(text_all, max_length=self.max_len, truncation=True,is_split_into_words=True)\n",
    "            input_ids = encoder_txt[\"input_ids\"]\n",
    "            token_type_ids = encoder_txt[\"token_type_ids\"]\n",
    "            attention_mask = encoder_txt[\"attention_mask\"]\n",
    "\n",
    "            return text, input_ids, token_type_ids, attention_mask,token_lengh,word_ids\n",
    "        else:\n",
    "            #TODO 测试\n",
    "            pass\n",
    "\n",
    "    def sequence_padding(self, inputs, length=None, value=0, seq_dims=1, mode='post'):\n",
    "        \"\"\"Numpy函数，将序列padding到同一长度\n",
    "        \"\"\"\n",
    "        if length is None:\n",
    "            length = np.max([np.shape(x)[:seq_dims] for x in inputs], axis=0)\n",
    "        elif not hasattr(length, '__getitem__'):\n",
    "            length = [length]\n",
    "\n",
    "        slices = [np.s_[:length[i]] for i in range(seq_dims)]\n",
    "        slices = tuple(slices) if len(slices) > 1 else slices[0]\n",
    "        pad_width = [(0, 0) for _ in np.shape(inputs[0])]\n",
    "\n",
    "        outputs = []\n",
    "        for x in inputs:\n",
    "            x = x[slices]\n",
    "            for i in range(seq_dims):\n",
    "                if mode == 'post':\n",
    "                    pad_width[i] = (0, length[i] - np.shape(x)[i])\n",
    "                elif mode == 'pre':\n",
    "                    pad_width[i] = (length[i] - np.shape(x)[i], 0)\n",
    "                else:\n",
    "                    raise ValueError('\"mode\" argument must be \"post\" or \"pre\".')\n",
    "            x = np.pad(x, pad_width, 'constant', constant_values=value)\n",
    "            outputs.append(x)\n",
    "\n",
    "        return np.array(outputs)\n",
    "\n",
    "    def collate(self, examples):\n",
    "        batch_input_ids, batch_attention_mask, batch_segment_ids,batch_token_lengh,batch_word_ids = [], [], [],[],[]\n",
    "        for item in examples:\n",
    "            raw_text, input_ids, token_type_ids, attention_mask,token_lengh,word_ids = self.encoder(item)\n",
    "            batch_input_ids.append(input_ids)\n",
    "            batch_segment_ids.append(token_type_ids)\n",
    "            batch_attention_mask.append(attention_mask)\n",
    "            batch_token_lengh.append([1]*token_lengh)\n",
    "            batch_word_ids.append(word_ids)\n",
    "        batch_inputids = torch.tensor(self.sequence_padding(batch_input_ids)).long()\n",
    "        batch_segmentids = torch.tensor(self.sequence_padding(batch_segment_ids)).long()\n",
    "        batch_attentionmask = torch.tensor(self.sequence_padding(batch_attention_mask)).float()\n",
    "\n",
    "        max_lengh = batch_inputids.shape[1]\n",
    "        batch_token_lengh = torch.tensor(self.sequence_padding(batch_token_lengh,length=max_lengh)).float()\n",
    "\n",
    "\n",
    "        return batch_inputids, batch_attentionmask, batch_segmentids,batch_token_lengh,batch_word_ids\n",
    "    def __getitem__(self, index):\n",
    "        item = self.data[index]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a890d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalPointer(nn.Module):\n",
    "    def __init__(self, encoder, ent_type_size, inner_dim, RoPE=True):\n",
    "        #encodr: RoBerta-Large as encoder\n",
    "        #inner_dim: 64\n",
    "        #ent_type_size: ent_cls_num\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.ent_type_size = ent_type_size\n",
    "        self.inner_dim = inner_dim\n",
    "        self.hidden_size = encoder.config.hidden_size\n",
    "        self.dense = nn.Linear(self.hidden_size, self.ent_type_size * self.inner_dim * 2)\n",
    "\n",
    "        self.RoPE = RoPE\n",
    "\n",
    "\n",
    "    def sinusoidal_position_embedding(self, batch_size, seq_len, output_dim):\n",
    "        position_ids = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(-1)\n",
    "\n",
    "        indices = torch.arange(0, output_dim // 2, dtype=torch.float)\n",
    "        indices = torch.pow(10000, -2 * indices / output_dim)\n",
    "        embeddings = position_ids * indices\n",
    "        embeddings = torch.stack([torch.sin(embeddings), torch.cos(embeddings)], dim=-1)\n",
    "        embeddings = embeddings.repeat((batch_size, *([1]*len(embeddings.shape))))\n",
    "        embeddings = torch.reshape(embeddings, (batch_size, seq_len, output_dim))\n",
    "        embeddings = embeddings.to(self.device)\n",
    "        return embeddings\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids,token_lengh):\n",
    "        self.device = input_ids.device\n",
    "        \n",
    "        context_outputs = self.encoder(input_ids, attention_mask, token_type_ids)\n",
    "        # last_hidden_state:(batch_size, seq_len, hidden_size)\n",
    "        last_hidden_state = context_outputs[0]\n",
    "\n",
    "        batch_size = last_hidden_state.size()[0]\n",
    "        seq_len = last_hidden_state.size()[1]\n",
    "\n",
    "        # outputs:(batch_size, seq_len, ent_type_size*inner_dim*2)\n",
    "        outputs = self.dense(last_hidden_state)\n",
    "        outputs = torch.split(outputs, self.inner_dim * 2, dim=-1)\n",
    "        # outputs:(batch_size, seq_len, ent_type_size, inner_dim*2)\n",
    "        outputs = torch.stack(outputs, dim=-2)\n",
    "        # qw,kw:(batch_size, seq_len, ent_type_size, inner_dim)\n",
    "        qw, kw = outputs[...,:self.inner_dim], outputs[...,self.inner_dim:]\n",
    "        if self.RoPE:\n",
    "            # pos_emb:(batch_size, seq_len, inner_dim)\n",
    "            pos_emb = self.sinusoidal_position_embedding(batch_size, seq_len, self.inner_dim)\n",
    "            # cos_pos,sin_pos: (batch_size, seq_len, 1, inner_dim)\n",
    "            cos_pos = pos_emb[..., None, 1::2].repeat_interleave(2, dim=-1)\n",
    "            sin_pos = pos_emb[..., None,::2].repeat_interleave(2, dim=-1)\n",
    "            qw2 = torch.stack([-qw[..., 1::2], qw[...,::2]], -1)\n",
    "            qw2 = qw2.reshape(qw.shape)\n",
    "            qw = qw * cos_pos + qw2 * sin_pos\n",
    "            kw2 = torch.stack([-kw[..., 1::2], kw[...,::2]], -1)\n",
    "            kw2 = kw2.reshape(kw.shape)\n",
    "            kw = kw * cos_pos + kw2 * sin_pos\n",
    "        # logits:(batch_size, ent_type_size, seq_len, seq_len)\n",
    "        logits = torch.einsum('bmhd,bnhd->bhmn', qw, kw)\n",
    "\n",
    "        # padding mask\n",
    "        pad_mask = token_lengh.unsqueeze(1).unsqueeze(1).expand(batch_size, self.ent_type_size, seq_len, seq_len)\n",
    "        logits = logits*pad_mask - (1-pad_mask)*1e12\n",
    "\n",
    "        # 排除下三角\n",
    "        mask = torch.tril(torch.ones_like(logits), -1)\n",
    "        logits = logits - mask * 1e12\n",
    "\n",
    "        return logits/self.inner_dim**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54df18b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionEmbedding(nn.Module):\n",
    "    \"\"\"定义Sin-Cos位置Embedding\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, output_dim, merge_mode='add', custom_position_ids=False):\n",
    "        super(SinusoidalPositionEmbedding, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.merge_mode = merge_mode\n",
    "        self.custom_position_ids = custom_position_ids\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if self.custom_position_ids:\n",
    "            seq_len = inputs.shape[1]\n",
    "            inputs, position_ids = inputs\n",
    "            position_ids = position_ids.type(torch.float)\n",
    "        else:\n",
    "            input_shape = inputs.shape\n",
    "            batch_size, seq_len = input_shape[0], input_shape[1]\n",
    "            position_ids = torch.arange(seq_len).type(torch.float)[None]\n",
    "        indices = torch.arange(self.output_dim // 2).type(torch.float)\n",
    "        indices = torch.pow(10000.0, -2 * indices / self.output_dim)\n",
    "        embeddings = torch.einsum('bn,d->bnd', position_ids, indices)\n",
    "        embeddings = torch.stack([torch.sin(embeddings), torch.cos(embeddings)], dim=-1)\n",
    "        embeddings = torch.reshape(embeddings, (-1, seq_len, self.output_dim))\n",
    "        if self.merge_mode == 'add':\n",
    "            return inputs + embeddings.to(inputs.device)\n",
    "        elif self.merge_mode == 'mul':\n",
    "            return inputs * (embeddings + 1.0).to(inputs.device)\n",
    "        elif self.merge_mode == 'zero':\n",
    "            return embeddings.to(inputs.device)\n",
    "class EffiGlobalPointer(nn.Module):\n",
    "    def __init__(self, encoder, ent_type_size, inner_dim, RoPE=True,fp16=False):\n",
    "        # encodr: RoBerta-Large as encoder\n",
    "        # inner_dim: 64\n",
    "        # ent_type_size: ent_cls_num\n",
    "        super(EffiGlobalPointer, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.ent_type_size = ent_type_size\n",
    "        self.inner_dim = inner_dim\n",
    "        self.hidden_size = encoder.config.hidden_size\n",
    "        self.RoPE = RoPE\n",
    "        self.fp16=fp16\n",
    "        if fp16:\n",
    "            self.epsilon=65504\n",
    "        else:\n",
    "            self.epsilon =1e12\n",
    "\n",
    "        self.dense_1 = nn.Linear(self.hidden_size, self.inner_dim * 2)\n",
    "        self.dense_2 = nn.Linear(self.hidden_size,\n",
    "                                 self.ent_type_size * 2)  # 原版的dense2是(inner_dim * 2, ent_type_size * 2)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "\n",
    "    def sequence_masking(self, x, mask, value='-inf', axis=None):\n",
    "\n",
    "        if mask is None:\n",
    "            return x\n",
    "        else:\n",
    "            if value == '-inf':\n",
    "                value = -self.epsilon\n",
    "            elif value == 'inf':\n",
    "                value = self.epsilon\n",
    "            assert axis > 0, 'axis must be greater than 0'\n",
    "            for _ in range(axis - 1):\n",
    "                mask = torch.unsqueeze(mask, 1)\n",
    "            for _ in range(x.ndim - mask.ndim):\n",
    "                mask = torch.unsqueeze(mask, mask.ndim)\n",
    "            return x * mask + value * (1 - mask)\n",
    "\n",
    "    def add_mask_tril(self, logits, mask):\n",
    "        if mask.dtype != logits.dtype:\n",
    "            mask = mask.type(logits.dtype)\n",
    "        logits = self.sequence_masking(logits, mask, '-inf', logits.ndim - 2)\n",
    "        logits = self.sequence_masking(logits, mask, '-inf', logits.ndim - 1)\n",
    "        # 排除下三角\n",
    "        mask = torch.tril(torch.ones_like(logits), diagonal=-1)\n",
    "        logits = logits - mask * self.epsilon\n",
    "        return logits\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids,token_lengh):\n",
    "        self.device = input_ids.device\n",
    "\n",
    "        context_outputs = self.encoder(input_ids, attention_mask, token_type_ids)\n",
    "        last_hidden_state = context_outputs.last_hidden_state\n",
    "        # batch_size = last_hidden_state.size()[0]\n",
    "        # seq_len = last_hidden_state.size()[1]\n",
    "        # outputs = self.dense_1(last_hidden_state)\n",
    "        out = self.drop(last_hidden_state)\n",
    "        logits1 = self.dense_1(self.dropout1(out))\n",
    "        logits2 = self.dense_1(self.dropout2(out))\n",
    "        logits3 = self.dense_1(self.dropout3(out))\n",
    "        logits4 = self.dense_1(self.dropout4(out))\n",
    "        logits5 = self.dense_1(self.dropout5(out))\n",
    "        outputs = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n",
    "\n",
    "        qw, kw = outputs[..., ::2], outputs[..., 1::2]  # 从0,1开始间隔为2\n",
    "        if self.RoPE:\n",
    "            pos = SinusoidalPositionEmbedding(self.inner_dim, 'zero')(outputs)\n",
    "            cos_pos = pos[..., 1::2].repeat_interleave(2, dim=-1)\n",
    "            sin_pos = pos[..., ::2].repeat_interleave(2, dim=-1)\n",
    "            qw2 = torch.stack([-qw[..., 1::2], qw[..., ::2]], 3)\n",
    "            qw2 = torch.reshape(qw2, qw.shape)\n",
    "            qw = qw * cos_pos + qw2 * sin_pos\n",
    "            kw2 = torch.stack([-kw[..., 1::2], kw[..., ::2]], 3)\n",
    "            kw2 = torch.reshape(kw2, kw.shape)\n",
    "            kw = kw * cos_pos + kw2 * sin_pos\n",
    "        logits = torch.einsum('bmd,bnd->bmn', qw, kw) / self.inner_dim ** 0.5\n",
    "        bias = torch.einsum('bnh->bhn', self.dense_2(last_hidden_state)) / 2\n",
    "        logits = logits[:, None] + bias[:, ::2, None] + bias[:, 1::2, :, None]  # logits[:, None] 增加一个维度\n",
    "        # print(token_lengh.size())\n",
    "        # pad_mask = token_lengh.unsqueeze(1).unsqueeze(1).expand(batch_size, self.ent_type_size, seq_len, seq_len)\n",
    "        # pad_mask = token_lengh.unsqueeze(1).unsqueeze(1).expand(batch_size, seq_len)\n",
    "        # print(pad_mask.size(),attention_mask.size())\n",
    "        # logits = self.add_mask_tril(logits, mask=attention_mask)\n",
    "        logits = self.add_mask_tril(logits, mask=token_lengh)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "658cf0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(logits, batch_tag,batchsize,batch_word_ids,fold_prob):\n",
    "    # batch_size, ent_type_size, seq_len, seq_len\n",
    "    pred_prob = logits.sigmoid()\n",
    "    sample_num = pred_prob.shape[0]\n",
    "    max_len = min(pred_prob.shape[2],256)\n",
    "    start_index = batch_tag*batchsize\n",
    "    for i in range(max_len):\n",
    "        span = min(ner_maxlen,max_len-i)\n",
    "        fold_prob[start_index:start_index+sample_num,:,i,:span]+=pred_prob[:,:,i,i:i+span].cpu().detach().numpy()\n",
    "    return fold_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69d522bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#单模型\n",
    "def inference_fn(test_loader, model, device,fold_prob):\n",
    "#     no_mark_num = 0\n",
    "#     pred_all = []\n",
    "#     true_all = []\n",
    "    model.eval()\n",
    "    tk0 = tqdm(test_loader,total=len(test_loader))\n",
    "    for batch_index,batch in enumerate(tk0):\n",
    "        input_ids, attention_mask, segment_ids,token_lengh,batch_word_ids = batch\n",
    "        input_ids, attention_mask, segment_ids,token_lengh = input_ids.to(device), attention_mask.to(\n",
    "            device), segment_ids.to(device),token_lengh.to(device)\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_ids, attention_mask, segment_ids,token_lengh)\n",
    "                fold_prob = get_pred(logits,batch_index,batchsize,batch_word_ids,fold_prob)\n",
    "    return fold_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab1df567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../input/dev_data.json'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4cbe746",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1025/1025 [00:00<00:00, 544059.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#初始化概率矩阵\n",
    "data = json.load(open(eval_file))\n",
    "sample_num = 0\n",
    "for item in tqdm(data, desc=\"Reading\" ):\n",
    "    sample_num += len(item[\"content\"])\n",
    "print(sample_num)\n",
    "# prob_result = np.zeros((sample_num,ENT_CLS_NUM,256,ner_maxlen),dtype= np.float32)\n",
    "# final_prob= [np.zeros((sample_num,ENT_CLS_NUM,256,ner_maxlen),dtype= np.float16)]*(CFG1.folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5cea19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_all = [CFG1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5547036d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from ../input/dev_data.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1025/1025 [00:00<00:00, 1653.03it/s]\n",
      "Some weights of the model checkpoint at /home/user0731/yankuo/SereTOD/pretrain/roformer were not used when initializing RoFormerModel: ['cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at /home/user0731/yankuo/SereTOD/pretrain/roformer and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 370/370 [02:05<00:00,  2.96it/s]\n"
     ]
    }
   ],
   "source": [
    "final_prob= []\n",
    "for i,cfg in enumerate(cfg_all):\n",
    "    for fold in range(1):\n",
    "        fold_prob= np.zeros((sample_num,ENT_CLS_NUM,256,ner_maxlen),dtype= np.float16)\n",
    "        ner_evl = EntDataset(load_data(eval_file), tokenizer=cfg.tokenizer,max_len=cfg.max_len)\n",
    "        ner_loader_evl = DataLoader(ner_evl, batch_size=cfg.batch_size, collate_fn=ner_evl.collate,shuffle=False,num_workers=cfg.num_workers)\n",
    "        if i == 0:\n",
    "            encoder = RoFormerModel.from_pretrained(cfg.model)\n",
    "        elif i == 3:\n",
    "            encoder = GAUAlphaModel.from_pretrained(cfg.model)\n",
    "        else:\n",
    "            encoder = AutoModel.from_pretrained(cfg.model)\n",
    "        if i==1:\n",
    "            model = EffiGlobalPointer(encoder, ENT_CLS_NUM, 64, fp16=True).to(device)\n",
    "        else:\n",
    "            model = GlobalPointer(encoder, ENT_CLS_NUM, 64).to(device)\n",
    "        # print(cfg.path+f\"ent_model{fold}.pth\")\n",
    "        state = torch.load(cfg.path+f\"ent_model0.pth\",map_location=device)\n",
    "        model.load_state_dict(state)\n",
    "        fold_prob = inference_fn(ner_loader_evl,model,device,fold_prob)\n",
    "        final_prob.append(fold_prob)\n",
    "        del encoder,model,state,fold_prob;gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b075b491-f728-40bf-a56c-f9489809c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存\n",
    "# np.savez_compressed('roformer/roformer', a=final_prob[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "983a250e-2579-4879-99e8-e05ed500f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_sample_token= []\n",
    "for sample in final_prob[0]:\n",
    "    per_pred = []\n",
    "    if (sample>0.5).sum==0:\n",
    "        preds_sample_token.append(per_pred)\n",
    "    else:\n",
    "        for l, start, end in zip(*np.where(sample > 0.5)):\n",
    "            if start != 0:\n",
    "                per_pred.append((l,start,start+end))\n",
    "    preds_sample_token.append(per_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02421536-c7f0-473d-8d02-cd85dde77db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1025/1025 [00:08<00:00, 122.28it/s]\n"
     ]
    }
   ],
   "source": [
    "#获得预测entity\n",
    "data = json.load(open(eval_file))\n",
    "pred_result = []\n",
    "idx = 0\n",
    "for item in tqdm(data):\n",
    "    pred_sample_char = {'id':item['id'],'entities':[],'triples':[]}\n",
    "    for turn in item[\"content\"]:\n",
    "        text_in_turn_list = []\n",
    "        for key in list(turn.keys())[:2]:\n",
    "            text_in_turn_list.append(turn[key])\n",
    "        text_in_turn = list(\"\".join(text_in_turn_list))\n",
    "        text_mapping = CFG1.tokenizer(text_in_turn,is_split_into_words=True)\n",
    "        word_ids = text_mapping.word_ids()\n",
    "        \n",
    "        for preds_sample in preds_sample_token[idx]:\n",
    "            start_char = word_ids[preds_sample[1]]\n",
    "            end_char = word_ids[preds_sample[2]]\n",
    "            type_ner = id2type[preds_sample[0]]\n",
    "            ent_name = ''.join(text_in_turn[start_char:end_char+1])\n",
    "            pred_sample_char['entities'].append({'name':ent_name,'type':type_ner,'position':[start_char,end_char]})\n",
    "    \n",
    "        idx += 1\n",
    "    pred_result.append(pred_sample_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c9dd5e-cb0e-432e-ac86-be7f41be6980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdcaefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cce461b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
